**NAMA : Nazwa Nabilla**

**NIM : 121450122**

**KELAS : RC**

# **TUGAS HARIAN TEKNOLOGI BASIS DATA**


```python
import numpy as np
import pickle
from pathlib import Path

# Path to the unzipped CIFAR data
data_dir = Path("/content/cifar-10-batches-py")

# Unpickle function provided by the CIFAR hosts
def unpickle(file):
    with open(file, "rb") as fo:
        dict = pickle.load(fo, encoding="bytes")
    return dict

images, labels = [], []
for batch in data_dir.glob("data_batch_*"):
    batch_data = unpickle(batch)
    for i, flat_im in enumerate(batch_data[b"data"]):
        im_channels = []
        # Each image is flattened, with channels in order of R, G, B
        for j in range(3):
            im_channels.append(
                flat_im[j * 1024 : (j + 1) * 1024].reshape((32, 32))
            )
        # Reconstruct the original image
        images.append(np.dstack((im_channels)))
        # Save the label
        labels.append(batch_data[b"labels"][i])

print("Loaded CIFAR-10 training set:")
print(f" - np.shape(images)     {np.shape(images)}")
print(f" - np.shape(labels)     {np.shape(labels)}")
```

    Loaded CIFAR-10 training set:
     - np.shape(images)     (50000, 32, 32, 3)
     - np.shape(labels)     (50000,)
    

perintah di atas bertujuan untuk
memuat dataset CIFAR-10 yang telah di-unpickle. CIFAR-10 adalah dataset populer yang berisi 60.000 gambar berwarna dengan resolusi rendah yang terbagi dalam 10 kelas.



## Setup for Storing Images on Disk


```python
#!pip install pillow
```

perintah di atas berfungsi untuk memasang pustaka Pillow agar dapat digunakan dalam pengembangan aplikasi atau skrip Python yang membutuhkan manipulasi gambar.

## Getting Started With LMDB


```python
#!pip install lmdb
```

perintah di atas untuk memasang pustaka LMDB agar dapat digunakan dalam pengembangan aplikasi atau skrip Python yang membutuhkan penyimpanan data key-value dengan kinerja tinggi.

## Getting Started With HDF5


```python
#!pip install h5py
```

perintah di atas ntuk memasang pustaka h5py agar dapat digunakan dalam pengembangan aplikasi atau skrip Python yang membutuhkan keterampilan untuk bekerja dengan file HDF5.





# Storing a Single Image


```python
from pathlib import Path

disk_dir = Path("data/disk/")
lmdb_dir = Path("data/lmdb/")
hdf5_dir = Path("data/hdf5/")
```


```python
disk_dir.mkdir(parents=True, exist_ok=True)
lmdb_dir.mkdir(parents=True, exist_ok=True)
hdf5_dir.mkdir(parents=True, exist_ok=True)
```

perintah di atas berguna untuk memastikan bahwa semua direktori yang diperlukan untuk penyimpanan data telah dibuat dengan benar sebelum melakukan operasi berikutnya, seperti menyimpan file atau mengakses basis data. Ini merupakan langkah awal yang penting dalam mengatur lingkungan penyimpanan data aplikasi.

## Storing to Disk


```python
from PIL import Image
import csv

def store_single_disk(image, image_id, label):
    """ Stores a single image as a .png file on disk.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    Image.fromarray(image).save(disk_dir / f"{image_id}.png")

    with open(disk_dir / f"{image_id}.csv", "wt") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        writer.writerow([label])
```

metadata label gambar disimpan dalam format .csv. File .csv dibuka dan ditulisi menggunakan modul csv dari Python. Label gambar dituliskan ke dalam file .csv dengan menggunakan csv.writer, dengan delimiter yang ditetapkan sebagai spasi, quotechar sebagai "|" (pipa), dan menggunakan metode writer.writerow() untuk menuliskan baris baru ke dalam file .csv. Nama file untuk metadata label gambar juga ditentukan berdasarkan image_id, dengan ekstensi .csv, dan disimpan dalam direktori yang sama dengan gambar. dengan ini memastikan bahwa setiap gambar yang disimpan ke dalam disk akan disertai dengan metadata labelnya dalam format .csv, yang memudahkan untuk analisis dan pemrosesan data lebih lanjut.

## Storing to LMDB


```python
class CIFAR_Image:
    def __init__(self, image, label):
        # Dimensions of image for reconstruction - not really necessary
        # for this dataset, but some datasets may include images of
        # varying sizes
        self.channels = image.shape[2]
        self.size = image.shape[:2]

        self.image = image.tobytes()
        self.label = label

    def get_image(self):
        """ Returns the image as a numpy array. """
        image = np.frombuffer(self.image, dtype=np.uint8)
        return image.reshape(*self.size, self.channels)
```

perintah di atas dapat mengemas gambar dan label CIFAR-10 ke dalam objek tunggal dan dengan mudah mengakses kembali gambar dalam bentuk array NumPy. Ini berguna jika kita ingin menyimpan atau memproses gambar dalam format yang lebih terstruktur, atau jika kita ingin memasukkan fungsi-fungsi lain yang berhubungan dengan manipulasi gambar ke dalam kelas ini.


```python
import lmdb
import pickle

def store_single_lmdb(image, image_id, label):
    """ Stores a single image to a LMDB.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    map_size = image.nbytes * 1024

    # Create a new LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), map_size=map_size)

    # Start a new write transaction
    with env.begin(write=True) as txn:
        # All key-value pairs need to be strings
        value = CIFAR_Image(image, label)
        key = f"{image_id:08}"
        txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()
```

perintah di atas bertujuan untuk menyimpan satu gambar ke dalam basis data LMDB (Lightning Memory-Mapped Database). Dengan melakukan ini, satu gambar beserta labelnya disimpan dalam basis data LMDB. Pendekatan ini memungkinkan untuk menyimpan dan mengakses gambar dengan efisien, terutama saat bekerja dengan jumlah data yang besar.





## Storing With HDF5


```python
import h5py

def store_single_hdf5(image, image_id, label):
    """ Stores a single image to an HDF5 file.
        Parameters:
        ---------------
        image       image array, (32, 32, 3) to be stored
        image_id    integer unique ID for image
        label       image label
    """
    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "image", np.shape(image), h5py.h5t.STD_U8BE, data=image
    )
    meta_set = file.create_dataset(
        "meta", np.shape(label), h5py.h5t.STD_U8BE, data=label
    )
    file.close()
```

dengan melakukan perintah di atas,satu gambar beserta labelnya disimpan dalam sebuah file HDF5. Pendekatan ini memungkinkan untuk menyimpan data dengan struktur yang terorganisir dan efisien, serta memungkinkan untuk memproses data dalam format HDF5 menggunakan berbagai alat analisis data yang mendukung format ini.

## Experiments for Storing a Single Image


```python
_store_single_funcs = dict(
    disk=store_single_disk, lmdb=store_single_lmdb, hdf5=store_single_hdf5
)
```

perintah di atas dapat dengan mudah mengakses fungsi-fungsi penyimpanan yang sesuai berdasarkan jenis penyimpanan yang diinginkan. Ini memungkinkan untuk fleksibilitas dalam memilih cara penyimpanan yang sesuai dengan kebutuhan aplikasi, serta memungkinkan untuk dengan mudah menambahkan atau mengubah fungsi-fungsi penyimpanan tanpa perlu mengubah kode yang lebih luas yang menggunakannya.


```python
from timeit import timeit

store_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_store_single_funcs[method](image, 0, label)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    store_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.021716976999869075
    Method: lmdb, Time usage: 0.012594325000009121
    Method: hdf5, Time usage: 0.002956076999907964
    

perintah di atas akan mendapatkan informasi tentang berapa lama waktu yang dibutuhkan untuk menyimpan satu gambar ke dalam setiap jenis penyimpanan. Ini berguna untuk membandingkan kinerja berbagai metode penyimpanan dan memilih yang paling efisien sesuai dengan kebutuhan aplikasi.

## Storing Many Images


```python
def store_many_disk(images, labels):
    """ Stores an array of images to disk
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Save all the images one by one
    for i, image in enumerate(images):
        Image.fromarray(image).save(disk_dir / f"{i}.png")

    # Save all the labels to the csv file
    with open(disk_dir / f"{num_images}.csv", "w") as csvfile:
        writer = csv.writer(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for label in labels:
            # This typically would be more than just one value per row
            writer.writerow([label])

def store_many_lmdb(images, labels):
    """ Stores an array of images to LMDB.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    map_size = num_images * images[0].nbytes * 10

    # Create a new LMDB DB for all the images
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), map_size=map_size)

    # Same as before â€” but let's write all the images in a single transaction
    with env.begin(write=True) as txn:
        for i in range(num_images):
            # All key-value pairs need to be Strings
            value = CIFAR_Image(images[i], labels[i])
            key = f"{i:08}"
            txn.put(key.encode("ascii"), pickle.dumps(value))
    env.close()

def store_many_hdf5(images, labels):
    """ Stores an array of images to HDF5.
        Parameters:
        ---------------
        images       images array, (N, 32, 32, 3) to be stored
        labels       labels array, (N, 1) to be stored
    """
    num_images = len(images)

    # Create a new HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "w")

    # Create a dataset in the file
    dataset = file.create_dataset(
        "images", np.shape(images), h5py.h5t.STD_U8BE, data=images
    )
    meta_set = file.create_dataset(
        "meta", np.shape(labels), h5py.h5t.STD_U8BE, data=labels
    )
    file.close()
```

dengan menggunakan fungsi-fungsi di atas dapat menyimpan sejumlah besar data gambar dan label ke dalam berbagai jenis penyimpanan secara efisien dan efektif. Ini memungkinkan untuk pengelolaan dan pemrosesan data yang lebih besar dalam konteks aplikasi machine learning dan vision.

## Preparing the Dataset


```python
cutoffs = [10, 100, 1000, 10000, 100000]

# Let's double our images so that we have 100,000
images = np.concatenate((images, images), axis=0)
labels = np.concatenate((labels, labels), axis=0)

# Make sure you actually have 100,000 images and labels
print(np.shape(images))
print(np.shape(labels))
```

    (100000, 32, 32, 3)
    (100000,)
    

## Experiment for Storing Many Images


```python
_store_many_funcs = dict(
    disk=store_many_disk, lmdb=store_many_lmdb, hdf5=store_many_hdf5
)

from timeit import timeit

store_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_store_many_funcs[method](images_, labels_)",
            setup="images_=images[:cutoff]; labels_=labels[:cutoff]",
            number=1,
            globals=globals(),
        )
        store_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.009025234999853637
    Method: lmdb, Time usage: 0.011818490999985443
    Method: hdf5, Time usage: 0.0025844360000064626
    Method: disk, Time usage: 0.06336309699986487
    Method: lmdb, Time usage: 0.0180822120000812
    Method: hdf5, Time usage: 0.0031017670000892394
    Method: disk, Time usage: 0.6023628140001165
    Method: lmdb, Time usage: 0.059414067999796316
    Method: hdf5, Time usage: 0.006250943000168263
    Method: disk, Time usage: 4.726475809000021
    Method: lmdb, Time usage: 0.380364211999904
    Method: hdf5, Time usage: 0.028290076000075715
    Method: disk, Time usage: 49.71381061400007
    Method: lmdb, Time usage: 9.059666912000012
    Method: hdf5, Time usage: 1.1248197510001319
    

kemudian selanjutnya dengan perintah di atas kita dapat memastikan bahwa kita memiliki 100.000 gambar dan label yang akan digunakan dalam eksperimen berikutnya. Ini penting untuk memastikan bahwa data yang diperlukan untuk eksperimen memiliki ukuran yang tepat.


```python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

    <ipython-input-44-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_41_1.png)
    


    <ipython-input-44-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_41_3.png)
    


perintah diatas dapat dengan mudah membandingkan waktu penyimpanan antara berbagai metode penyimpanan (PNG files, LMDB, dan HDF5) dalam konteks jumlah gambar yang berbeda. Ini membantu dalam mengevaluasi kinerja dan efisiensi dari masing-masing metode penyimpanan.






```python
import matplotlib.pyplot as plt

def plot_with_legend(
    x_range, y_data, legend_labels, x_label, y_label, title, log=False
):
    """ Displays a single plot with multiple datasets and matching legends.
        Parameters:
        --------------
        x_range         list of lists containing x data
        y_data          list of lists containing y values
        legend_labels   list of string legend labels
        x_label         x axis label
        y_label         y axis label
    """
    plt.style.use("seaborn-whitegrid")
    plt.figure(figsize=(10, 7))

    if len(y_data) != len(legend_labels):
        raise TypeError(
            "Error: number of data sets does not match number of labels."
        )

    all_plots = []
    for data, label in zip(y_data, legend_labels):
        if log:
            temp, = plt.loglog(x_range, data, label=label)
        else:
            temp, = plt.plot(x_range, data, label=label)
        all_plots.append(temp)

    plt.title(title)
    plt.xlabel(x_label)
    plt.ylabel(y_label)
    plt.legend(handles=all_plots)
    plt.show()

# Getting the store timings data to display
disk_x = store_many_timings["disk"]
lmdb_x = store_many_timings["lmdb"]
hdf5_x = store_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Storage time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x, lmdb_x, hdf5_x],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to store",
    "Log storage time",
    log=True,
)
```

    <ipython-input-45-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_43_1.png)
    


    <ipython-input-45-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_43_3.png)
    


perintah kode ini menggunakan fungsi plot_with_legend untuk membuat dua plot yang menunjukkan waktu yang dibutuhkan untuk menyimpan data dalam format PNG, LMDB, dan HDF5 sebagai fungsi dari jumlah gambar yang disimpan. /

1. Plot pertama menampilkan waktu penyimpanan sebagai fungsi dari jumlah gambar yang disimpan. Waktu penyimpanan diplot dalam sumbu y, sementara jumlah gambar diplot dalam sumbu x. Plot ini memberikan gambaran tentang kinerja relatif dari tiga metode penyimpanan yang berbeda (PNG files, LMDB, dan HDF5) dalam mengelola jumlah gambar yang berbeda.
2. Plot kedua adalah plot log-log yang menunjukkan waktu penyimpanan dalam skala logaritmik pada kedua sumbu. Plot log-log ini berguna untuk memvisualisasikan hubungan antara waktu penyimpanan dan jumlah gambar dengan lebih baik, terutama ketika ada perbedaan skala yang besar di antara kedua variabel tersebut. Dengan melakukan ini, kita dapat dengan mudah memeriksa keterkaitan antara waktu penyimpanan dan jumlah gambar dalam berbagai skenario.\
Keduanya memungkinkan untuk membandingkan kinerja relatif dari berbagai metode penyimpanan dalam berbagai skenario jumlah gambar yang berbeda. Ini membantu dalam mengevaluasi efisiensi dan skalabilitas dari masing-masing metode penyimpanan.

## Reading a Single Image


```python
def read_single_disk(image_id):
    """ Stores a single image to disk.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    image = np.array(Image.open(disk_dir / f"{image_id}.png"))

    with open(disk_dir / f"{image_id}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        label = int(next(reader)[0])

    return image, label
```

fungsi ini memungkinkan untuk membaca gambar dan label yang terkait dari disk dengan cara yang mudah dan efisien. Ini berguna dalam aplikasi di mana data perlu dibaca dari penyimpanan persisten seperti disk untuk diproses lebih lanjut.

## Reading From LMDB


```python
def read_single_lmdb(image_id):
    """ Stores a single image to LMDB.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the LMDB environment
    env = lmdb.open(str(lmdb_dir / f"single_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Encode the key the same way as we stored it
        data = txn.get(f"{image_id:08}".encode("ascii"))
        # Remember it's a CIFAR_Image object that is loaded
        cifar_image = pickle.loads(data)
        # Retrieve the relevant bits
        image = cifar_image.get_image()
        label = cifar_image.label
    env.close()

    return image, label
```

## Reading From HDF5


```python
def read_single_hdf5(image_id):
    """ Stores a single image to HDF5.
        Parameters:
        ---------------
        image_id    integer unique ID for image

        Returns:
        ----------
        image       image array, (32, 32, 3) to be stored
        label       associated meta data, int label
    """
    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{image_id}.h5", "r+")

    image = np.array(file["/image"]).astype("uint8")
    label = int(np.array(file["/meta"]).astype("uint8"))

    return image, label
```

Fungsi read_single_lmdb bertujuan untuk membaca satu gambar dan metadata label yang terkait dari basis data LMDB. \
Fungsi mengembalikan gambar dalam bentuk array NumPy dan metadata label dalam bentuk integer.

Dengan melakukan ini, fungsi ini memungkinkan untuk membaca gambar dan label yang terkait dari basis data LMDB dengan cara yang mudah dan efisien. Ini berguna dalam aplikasi di mana data perlu dibaca dari basis data untuk diproses lebih lanjut.


```python
_read_single_funcs = dict(
    disk=read_single_disk, lmdb=read_single_lmdb, hdf5=read_single_hdf5
)
```

Baris ini mendefinisikan kamus _read_single_funcs yang berisi tiga pasangan kunci-nilai, di mana kunci-kunci tersebut adalah string yang merepresentasikan tiga jenis sumber data yang berbeda ("disk", "lmdb", "hdf5"), sedangkan nilai-nilainya adalah fungsi-fungsi yang bertugas untuk membaca data dari masing-masing jenis sumber data tersebut.

Dengan menggunakan kamus ini, kita dapat dengan mudah mengakses fungsi-fungsi pembaca data yang sesuai berdasarkan jenis sumber data yang diinginkan. Ini memungkinkan untuk fleksibilitas dalam memilih cara membaca data yang sesuai dengan kebutuhan aplikasi, serta memungkinkan untuk dengan mudah menambahkan atau mengubah fungsi-fungsi pembaca data tanpa perlu mengubah kode yang lebih luas yang menggunakannya.

## Experiment for Reading a Single Image


```python
from timeit import timeit

read_single_timings = dict()

for method in ("disk", "lmdb", "hdf5"):
    t = timeit(
        "_read_single_funcs[method](0)",
        setup="image=images[0]; label=labels[0]",
        number=1,
        globals=globals(),
    )
    read_single_timings[method] = t
    print(f"Method: {method}, Time usage: {t}")
```

    Method: disk, Time usage: 0.0015743050000764924
    Method: lmdb, Time usage: 0.008304685999974026
    Method: hdf5, Time usage: 0.0019576219999635214
    

Dalam setiap iterasi loop for, kita menggunakan fungsi timeit untuk mengukur waktu eksekusi dari pemanggilan fungsi pembaca data yang sesuai. Argumen setup digunakan untuk menetapkan variabel image dan label menggunakan gambar pertama dari array images dan label pertama dari array labels. Fungsi pembaca data kemudian dipanggil dengan menggunakan metode yang sesuai dari kamus _read_single_funcs.

Hasil waktu eksekusi disimpan dalam kamus read_single_timings dengan kunci yang sesuai (metode pembaca data). Kemudian, hasil waktu juga dicetak untuk setiap metode pembaca data.

Dengan melakukan ini, kita mendapatkan informasi tentang berapa lama waktu yang dibutuhkan untuk membaca satu gambar dari setiap jenis sumber data. Ini berguna untuk membandingkan kinerja berbagai metode pembaca data dan memilih yang paling efisien sesuai dengan kebutuhan aplikasi.





# Reading Many Images

## Adjusting the Code for Many Images


```python
def read_many_disk(num_images):
    """ Reads image from disk.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Loop over all IDs and read each image in one by one
    for image_id in range(num_images):
        images.append(np.array(Image.open(disk_dir / f"{image_id}.png")))

    with open(disk_dir / f"{num_images}.csv", "r") as csvfile:
        reader = csv.reader(
            csvfile, delimiter=" ", quotechar="|", quoting=csv.QUOTE_MINIMAL
        )
        for row in reader:
            labels.append(int(row[0]))
    return images, labels

def read_many_lmdb(num_images):
    """ Reads image from LMDB.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []
    env = lmdb.open(str(lmdb_dir / f"{num_images}_lmdb"), readonly=True)

    # Start a new read transaction
    with env.begin() as txn:
        # Read all images in one single transaction, with one lock
        # We could split this up into multiple transactions if needed
        for image_id in range(num_images):
            data = txn.get(f"{image_id:08}".encode("ascii"))
            # Remember that it's a CIFAR_Image object
            # that is stored as the value
            cifar_image = pickle.loads(data)
            # Retrieve the relevant bits
            images.append(cifar_image.get_image())
            labels.append(cifar_image.label)
    env.close()
    return images, labels

def read_many_hdf5(num_images):
    """ Reads image from HDF5.
        Parameters:
        ---------------
        num_images   number of images to read

        Returns:
        ----------
        images      images array, (N, 32, 32, 3) to be stored
        labels      associated meta data, int label (N, 1)
    """
    images, labels = [], []

    # Open the HDF5 file
    file = h5py.File(hdf5_dir / f"{num_images}_many.h5", "r+")

    images = np.array(file["/images"]).astype("uint8")
    labels = np.array(file["/meta"]).astype("uint8")

    return images, labels

_read_many_funcs = dict(
    disk=read_many_disk, lmdb=read_many_lmdb, hdf5=read_many_hdf5
)
```

Setiap fungsi ini menerima argumen num_images yang menentukan jumlah gambar yang akan dibaca. Setelah membaca data, fungsi-fungsi ini mengembalikan array gambar dalam bentuk NumPy dan metadata label dalam bentuk array NumPy juga.

Selanjutnya, kamus _read_many_funcs didefinisikan yang berisi tiga pasangan kunci-nilai, di mana kunci-kunci tersebut adalah string yang merepresentasikan tiga jenis sumber data yang berbeda ("disk", "lmdb", "hdf5"), sedangkan nilai-nilainya adalah fungsi-fungsi yang bertugas untuk membaca data dari masing-masing jenis sumber data tersebut.

Dengan menggunakan kamus ini, kita dapat dengan mudah mengakses fungsi-fungsi pembaca data yang sesuai berdasarkan jenis sumber data yang diinginkan. Ini memungkinkan untuk fleksibilitas dalam membaca data yang sesuai dengan kebutuhan aplikasi, serta memungkinkan untuk dengan mudah menambahkan atau mengubah fungsi-fungsi pembaca data tanpa perlu mengubah kode yang lebih luas yang menggunakannya.

## Experiment for Reading Many Images


```python
from timeit import timeit

read_many_timings = {"disk": [], "lmdb": [], "hdf5": []}

for cutoff in cutoffs:
    for method in ("disk", "lmdb", "hdf5"):
        t = timeit(
            "_read_many_funcs[method](num_images)",
            setup="num_images=cutoff",
            number=1,
            globals=globals(),
        )
        read_many_timings[method].append(t)

        # Print out the method, cutoff, and elapsed time
        print(f"Method: {method}, No. images: {cutoff}, Time usage: {t}")
```

    Method: disk, No. images: 10, Time usage: 0.007932493999987855
    Method: lmdb, No. images: 10, Time usage: 0.009093602000120882
    Method: hdf5, No. images: 10, Time usage: 0.002738822000083019
    Method: disk, No. images: 100, Time usage: 0.03088707799997792
    Method: lmdb, No. images: 100, Time usage: 0.013703069000030155
    Method: hdf5, No. images: 100, Time usage: 0.010327887000130431
    Method: disk, No. images: 1000, Time usage: 0.29719100700003764
    Method: lmdb, No. images: 1000, Time usage: 0.05198593099999016
    Method: hdf5, No. images: 1000, Time usage: 0.0064375619999736955
    Method: disk, No. images: 10000, Time usage: 2.803717513000038
    Method: lmdb, No. images: 10000, Time usage: 0.18789651499992033
    Method: hdf5, No. images: 10000, Time usage: 0.02813696900011564
    Method: disk, No. images: 100000, Time usage: 29.397559792000038
    Method: lmdb, No. images: 100000, Time usage: 1.468439953999905
    Method: hdf5, No. images: 100000, Time usage: 1.139051696000024
    

Di dalam loop tersebut, kita juga memiliki loop kedua yang mengiterasi melalui setiap jenis sumber data ("disk", "lmdb", "hdf5"). Pada setiap iterasi loop kedua, kita menggunakan fungsi timeit untuk mengukur waktu eksekusi dari pemanggilan fungsi pembaca data yang sesuai (_read_many_funcs[method]) dengan jumlah gambar yang sesuai (num_images) yang ditetapkan oleh nilai cutoff saat ini.

Hasil waktu eksekusi dicatat dalam kamus read_many_timings dengan kunci yang sesuai (metode pembaca data). Selain itu, waktu eksekusi juga dicetak untuk setiap metode pembaca data, jumlah gambar, dan metode bacaannya.

Dengan melakukan ini, kita mendapatkan informasi tentang berapa lama waktu yang dibutuhkan untuk membaca sejumlah gambar dari setiap jenis sumber data dengan berbagai ukuran dataset yang berbeda. Ini berguna untuk membandingkan kinerja berbagai metode pembaca data dalam mengelola jumlah data yang berbeda-beda.







```python
disk_x_r = read_many_timings["disk"]
lmdb_x_r = read_many_timings["lmdb"]
hdf5_x_r = read_many_timings["hdf5"]

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Read time",
    log=False,
)

plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r],
    ["PNG files", "LMDB", "HDF5"],
    "Number of images",
    "Seconds to read",
    "Log read time",
    log=True,
)
```

    <ipython-input-45-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_65_1.png)
    


    <ipython-input-45-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_65_3.png)
    


Dua plot dihasilkan di sini menggunakan fungsi plot_with_legend. Plot-plott tersebut menunjukkan waktu yang diperlukan untuk membaca sejumlah gambar dari tiga jenis sumber data yang berbeda ("disk", "lmdb", "hdf5") sebagai fungsi dari jumlah gambar yang dibaca.

1. Plot pertama menampilkan waktu baca sebagai fungsi dari jumlah gambar yang dibaca. Waktu baca diplot dalam sumbu y, sedangkan jumlah gambar diplot dalam sumbu x. Plot ini memberikan gambaran tentang kinerja relatif dari tiga metode baca data yang berbeda dalam mengelola jumlah gambar yang berbeda.
2. Plot kedua adalah plot log-log yang menunjukkan waktu baca dalam skala logaritmik pada kedua sumbu. Plot log-log ini berguna untuk memvisualisasikan hubungan antara waktu baca dan jumlah gambar dengan lebih baik, terutama ketika ada perbedaan skala yang besar di antara kedua variabel tersebut. Dengan melakukan ini, kita dapat dengan mudah memeriksa keterkaitan antara waktu baca dan jumlah gambar dalam berbagai skenario.\
\
Kedua plot tersebut memberikan gambaran yang jelas tentang kinerja pembacaan data dari tiga jenis sumber data yang berbeda dalam berbagai skenario jumlah gambar yang berbeda. Ini membantu dalam mengevaluasi efisiensi dan skalabilitas dari masing-masing metode pembaca data, serta membantu dalam memilih metode yang paling sesuai dengan kebutuhan aplikasi.






```python
plot_with_legend(
    cutoffs,
    [disk_x_r, lmdb_x_r, hdf5_x_r, disk_x, lmdb_x, hdf5_x],
    [
        "Read PNG",
        "Read LMDB",
        "Read HDF5",
        "Write PNG",
        "Write LMDB",
        "Write HDF5",
    ],
    "Number of images",
    "Seconds",
    "Log Store and Read Times",
    log=False,
)
```

    <ipython-input-45-99d89538a067>:15: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.
      plt.style.use("seaborn-whitegrid")
    


    
![png](output_67_1.png)
    


Plot yang dihasilkan di sini menggunakan fungsi plot_with_legend dengan jumlah data yang lebih besar untuk memberikan gambaran komprehensif tentang waktu yang diperlukan untuk penyimpanan dan pembacaan data dari tiga jenis sumber data yang berbeda ("disk", "lmdb", "hdf5").

Plot ini menunjukkan waktu yang diperlukan untuk menyimpan dan membaca sejumlah gambar sebagai fungsi dari jumlah gambar yang dibaca. Waktu pembacaan ditunjukkan untuk setiap jenis sumber data ("PNG files", "LMDB", "HDF5") dengan kurva biru, hijau, dan oranye masing-masing. Sementara itu, waktu penyimpanan ditunjukkan untuk setiap jenis sumber data dengan kurva merah, ungu, dan kuning.

Penambahan waktu penyimpanan memberikan perspektif tambahan pada kinerja keseluruhan dari masing-masing metode dalam mengelola data. Dengan menyajikan waktu penyimpanan dan pembacaan bersama-sama, kita dapat melihat perbandingan langsung antara waktu yang dibutuhkan untuk dua operasi ini.

Plot ini membantu dalam mengevaluasi secara menyeluruh kinerja relatif dari tiga jenis sumber data yang berbeda dalam hal waktu yang diperlukan untuk operasi penyimpanan dan pembacaan data, serta memungkinkan untuk memilih metode yang paling sesuai dengan kebutuhan aplikasi.
